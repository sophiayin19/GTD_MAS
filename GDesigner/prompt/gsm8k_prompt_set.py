import yaml
from typing import Dict, Any, Union, List
import itertools
from .prompt_set import PromptSet
from .prompt_set_registry import PromptSetRegistry
from .common import get_combine_materials
from ..utils.const import GDesigner_ROOT

@PromptSetRegistry.register("gsm8k")
class GSM8KPromptSet(PromptSet):
    def __init__(self,
                 config_path: str = "config/gsm8k_config.yaml",
                 **kwargs):
        with open(config_path, 'r') as file:
            self.config = yaml.safe_load(file)
        self.roles = itertools.cycle(self.config['roles'])


    def get_role(self):
        return next(self.roles)

    def get_constraint(self, role):
        return self.config['role_description'][role]

    def get_description(self, role):
        return self.config['role_description'][role]
    
    def get_role_connection(self):
        return self.config['role_connection']
    
    def get_format(self):
        return "natural language"

    def get_answer_prompt(self, question, **kwargs):
        # Format the question for the AI assistant to answer
        return f"{question}"

    def get_react_prompt(self, question, solution, feedback):
        return f"""Here is an unsuccessful attempt for solving the folloing question:
Question:
{question}
Attempted Solution:
{solution}
Feedback:\n{feedback}
Rewrite the code based on the feedback and the following question:
{question}"""


    def get_query_prompt(self, question):
        return (
"# Information Gathering for Question Resolution\n\n"
"Evaluate if additional information is needed to answer the question. "
"If a web search or file analysis is necessary, outline specific clues or details to be searched for.\n\n"
f"## â“ Target Question:\n{question}\n\n"
"## ðŸ” Clues for Investigation:\n"
"Identify critical clues and concepts within the question that are essential for finding the answer.\n"
        )


    def get_file_analysis_prompt(self, query, file):
        return (
"# File Analysis Task\n\n"
f"## ðŸ” Information Extraction Objective:\n---\n{query}\n---\n\n"
f"## ðŸ“„ File Under Analysis:\n---\n{file}\n---\n\n"
"## ðŸ“ Instructions:\n"
"1. Identify the key sections in the file relevant to the query.\n"
"2. Extract and summarize the necessary information from these sections.\n"
"3. Ensure the response is focused and directly addresses the query.\n"
"Example: 'Identify the main theme in the text.'"
        )


    def get_websearch_prompt(self, question, query):
        return (
            "# Web Search Task\n\n"
            f"## Original Question: \n---\n{question}\n---\n\n"
            f"## ðŸ” Targeted Search Objective:\n---\n{query}\n---\n\n"
            "## ðŸŒ Simplified Search Instructions:\n"
            "Generate three specific search queries directly related to the original question. Each query should focus on key terms from the question. Format the output as a comma-separated list.\n"
            "For example, if the question is 'Who will be the next US president?', your queries could be: 'US presidential candidates, current US president, next US president'.\n"
            "Remember to format the queries as 'query1, query2, query3'."
        )



    def get_adversarial_answer_prompt(self, question):
        pass


    def get_distill_websearch_prompt(self, question, query, results):
        return (
"# Summarization of Search Results\n\n"
f"## Original question: \n---\n{question}\n---\n\n"
f"## ðŸ” Required Information for Summary:\n---\n{query}\n---\n\n"
f"## ðŸŒ Analyzed Search Results:\n---\n{results}\n---\n\n"
"## ðŸ“ Instructions for Summarization:\n"
"1. Review the provided search results and identify the most relevant information related to the question and query.\n"
"2. Extract and highlight the key findings, facts, or data points from these results.\n"
"3. Organize the summarized information in a coherent and logical manner.\n"
"4. Ensure the summary is concise and directly addresses the query, avoiding extraneous details.\n"  
"5. If the information from web search is useless, directly answer: \"No useful information from WebSearch\".\n"  
        )


    def get_reflect_prompt(self, question, answer):
        return (
"# Reflection on the Task\n\n"
f"## ðŸ¤” Reflection Question:\n---\n{question}\n---\n\n"
f"## ðŸ’¡ Your Previous Answer:\n---\n{answer}\n---\n\n"
"## âœï¸ Instructions:\n"
"Reflect on your answer process, considering the accuracy, method, and reasoning."
        )


    def get_self_consistency(self, question: str, answers: list, constraint: str) -> str:
        formatted_answers = "\n".join([f"Answer {index + 1}: {answer}" for index, answer in enumerate(answers)])
        return (
"# Self-Consistency Evaluation Task\n\n"
f"## ðŸ¤” Question for Review:\n---\n{question}\n---\n\n"
f"## ðŸ’¡ Reviewable Answers:\n---\n{formatted_answers}\n---\n\n"
"## ðŸ“‹ Instructions for Selection:\n"
"1. Read each answer and assess how it addresses the question.\n"
"2. Compare the answers for their adherence to the given question's criteria and logical coherence.\n"
"3. Identify the answer that best aligns with the question's requirements and is the most logically consistent.\n"
"4. Ignore the candidate answers if they do not give a direct answer, for example, using 'unable to ...', 'as an AI ...'.\n"
"5. Copy the most suitable answer as it is, without modification, to maintain its original form.\n"
f"6. Adhere to the constraints: {constraint}.\n"
"Note: If no answer fully meets the criteria, choose and copy the one that is closest to the requirements."
        )

    def get_select_best(self, question: str, answers: list, constraint: str) -> str:
        formatted_answers = "\n".join([f"Answer {index + 1}: {answer}" for index, answer in enumerate(answers)])
        return (
"# Best Answer Evaluation Task\n\n"
f"## ðŸ¤” Question:\n---\n{question}\n---\n\n"
f"## ðŸ’¡ Candidate Answers for Evaluation:\n---\n{formatted_answers}\n---\n\n"
"## ðŸ“‹ Evaluation Instructions:\n"
"1. Examine the question closely to understand its requirements.\n"
"2. Read each candidate answer thoroughly and assess its relevance and accuracy about the question.\n"
"3. Choose the answer that most accurately and completely addresses the question.\n"
"4. Ignore the candidate answers if they do not give a direct answer, for example, using 'unable to ...', 'as an AI ...'.\n"
"5. Copy the chosen answer exactly as it is presented, maintaining its original format.\n"
f"6. Adhere to the constraints: {constraint}.\n"
"Note: If no answer fully meets the criteria, choose and copy the one that is closest to the requirements."
        )

    def get_combine_materials(self, materials: Dict[str, Any]) -> str:
        return get_combine_materials(materials)

    def get_decision_constraint(self):
        return self.config['decision_constraint']

    def get_decision_role(self):
        return self.config['decision_role']

    def get_decision_few_shot(self):
        return "\n".join(self.config['decision_few_shot'])

